High level summary (one-liner)

A frontend lets a user pick model(s) and either (A) pay per prompt via x402 or (B) top up credits via x402. The backend enforces payment using x402 (HTTP 402 flow), forwards the prompt to your subscribed LLM provider, streams tokens back to the client, and logs metering for reconciliation.

Key x402 facts: servers respond 402 Payment Required with a JSON “payment requirements” object; client pays onchain and retries with payment proof; server verifies and serves response. This is the core loop you will implement. 
Coinbase Developer Docs
+1

Phase plan (what to build, in order)

Design & infra (1–2 hours)

Pick LLM provider (OpenAI/Anthropic/HF) for initial integration (choose one for MVP).

Choose Solana (or Base/EVM) testnet to develop x402 flow. Use Coinbase x402 docs & Solana x402 quickstarts. 
Coinbase Developer Docs
+1

Backend: core x402 seller + LLM proxy (6–10 hours) — MVP priority

Implement GET /api/query which returns 402 with payment requirements if unpaid.

Implement POST /api/verify or server-side payment verification to accept x402 payments and then call the LLM.

Implement streaming relay (SSE or WebSocket) to push LLM tokens to client.

Frontend: wallet + UI (4–8 hours) — MVP priority

Simple web UI (React/Next) with: model selector, input box, “pay” or “use credits,” streaming results, and wallet connection (Phantom / WalletConnect).

Show onchain receipt link / tx explorer for demo.

Credits & top-up flow (2–4 hours)

Implement credits purchase via single x402 payment; store credits on server; use credits for subsequent prompts without new payments.

Polish & demo features (4–8 hours)

Live cost meter while streaming, multi-model compare, agent demo (autopay), receipts, rate limiting, and logging.

Tech stack (recommended for fastest hackathon delivery)

Backend: Node.js + Express (fast to prototype).

Streaming: Server-Sent Events (SSE) or WebSocket; SSE is simpler for server→client streaming.

Database: SQLite / Postgres (use SQLite for hackathon).

Wallet: Phantom (browser extension) / Solflare / WalletConnect for mobile.

LLM provider: OpenAI streaming API (or Anthropic/HF) — use whichever you have keys for.

x402: use Coinbase / official x402 SDKs or minimal server verifier following docs. 
Coinbase Developer Docs
+1

Data model (simple)

Use a users table only if you want persistence; otherwise anonymous wallet address is fine.

payments:

id (uuid)

wallet_address

amount_requested_usd (or in USDC)

currency (USDC)

recipient_address

status: pending/confirmed/settled

prompt_id (FK)

prompts:

id

wallet_address

prompt_text

model_requested

cost_estimate

token_count (post)

response_snippet

created_at

credits:

wallet_address

credits_balance (float)

last_topup_tx

Core API flows (endpoints + JSON examples)
1) Request a paid LLM response (client → server)

Client calls:

POST /api/query
Content-Type: application/json
Body: { "model": "gpt-4o-mini", "prompt": "Summarize my resume", "mode": "pay-per-prompt" }

Server behavior (MVP):

Compute price estimate (e.g., $0.01 + token-estimate).

If client has valid credits, deduct and proceed to call LLM.

Otherwise, return HTTP 402 Payment Required with a JSON payment requirements object per x402 spec (accepted currencies, amount, recipient, timeout, payment scheme). Example body:

HTTP/1.1 402 Payment Required
Content-Type: application/json
{
  "payment_required": true,
  "accepts": [
    {
      "scheme":"solana",
      "token_contract":"USDC-ADDRESS-ON-SOLANA",
      "recipient":"your_seller_wallet_address",
      "amount":"0.01",
      "unit":"USDC",
      "timeout":"120"
    }
  ],
  "request_id":"<uuid>"
}


(Clients implement x402: they pay onchain and retry with payment proof headers.) 
Avalanche Builder Hub
+1

2) Client pays and retries with payment proof

After payment, client retries the same POST /api/query but now includes payment proof header (x402 flow uses an X-Payment or similar header containing transaction reference). Example:

POST /api/query
Headers:
  X-Payment: <onchain_tx_signature_or_payment_proof_json>
Body: same as before

Server verifies payment:

Verify transaction onchain (RPC or SDK), ensure funds transferred to recipient and amount ≥ required.

Mark payment confirmed.

Proceed to call LLM.

3) Stream the LLM response

After verifying payment, server calls the LLM with streaming enabled and relays tokens to the client.

Option A — SSE (Server Sent Events)

Client opens GET /api/stream/:prompt_id via EventSource after server accepted payment; server pushes data: events as tokens arrive.

Option B — WebSocket

Use a single WebSocket connection and stream {"token":"...","meta":{}} messages.

Minimal server skeleton (Node/Express + SSE + pseudo x402 verify)

Below is conceptual code (trimmed for clarity). You will replace verifyPaymentOnchain() and callLLMStream() with real implementations.

// server.js (simplified)
import express from 'express';
import bodyParser from 'body-parser';
import { v4 as uuidv4 } from 'uuid';

const app = express();
app.use(bodyParser.json());

/* Helper: price estimator */
function estimatePrice(prompt, model) {
  // naive: base + per token estimate
  return 0.01; // USD or USDC units for demo
}

/* POST /api/query */
app.post('/api/query', async (req, res) => {
  const { model, prompt, payment_proof, mode, wallet } = req.body;
  const requestId = uuidv4();
  const price = estimatePrice(prompt, model);

  // check credits (pseudocode)
  if (mode === 'credits' && await hasCredits(wallet, price)) {
    await deductCredits(wallet, price);
    // create prompt record and start LLM streaming
    const promptId = await createPromptRecord({ wallet, prompt, model, price, status:'processing' });
    return res.json({ ok:true, promptId, streamUrl:`/api/stream/${promptId}` });
  }

  // if payment proof absent => return 402 with payment requirements per x402
  if (!payment_proof) {
    return res.status(402).json({
      payment_required:true,
      accepts:[{
        scheme:"solana",
        token_contract:"<USDC_TOKEN_ADDRESS>",
        recipient:"<YOUR_SELLER_WALLET>",
        amount: String(price),
        unit:"USDC",
        timeout:120
      }],
      request_id: requestId
    });
  }

  // verify provided payment proof onchain
  const ok = await verifyPaymentOnchain(payment_proof, price);
  if (!ok) return res.status(402).json({error:'payment_not_verified'});

  // Payment verified -- create prompt and return stream URL
  const promptId = await createPromptRecord({ wallet, prompt, model, price, status:'processing' });
  // kick off LLM call in background (or synchronously if you stream immediately)
  startLLMStreamingToPrompt(promptId, prompt, model);
  res.json({ ok:true, promptId, streamUrl:`/api/stream/${promptId}` });
});

/* SSE stream endpoint */
app.get('/api/stream/:promptId', async (req, res) => {
  const promptId = req.params.promptId;
  res.set({
    'Content-Type': 'text/event-stream',
    'Cache-Control': 'no-cache',
    Connection: 'keep-alive'
  });
  res.flushHeaders();

  // subscribe to token events for this prompt (in memory/simple pubsub)
  subscribeToPrompt(promptId, (token) => {
    res.write(`data: ${JSON.stringify({ token })}\n\n`);
  });

  // send done event when LLM finished
});


Notes: verifyPaymentOnchain() will call the Solana RPC (or Coinbase x402 verifier) to ensure tx succeeded and recipient received the expected stablecoin. For the hackathon, use testnet + small amounts.

LLM streaming relay (concept)

Use the LLM provider streaming API (OpenAI-style) which returns tokens incrementally.

For each token chunk received from provider: publish it to your SSE/WebSocket subscribers for promptId.

Track tokens consumed for final reconciliation and cost accounting.

Credit (top-up) flow

Client clicks “Top up $X” → call POST /api/topup → server returns a x402 payment requirement (like above) for the credit amount.

Client pays via wallet; server verifies transaction; server increments credits_balance for wallet.

After topup, client can call POST /api/query and the server deducts from credits without doing x402 every time.

This reduces friction demo-wise (only one wallet signature).

Wallet & client integration (UX)

Connect wallet in frontend (Phantom). For web: window.solana or @solana/wallet-adapter-react.

When receiving 402 payment requirements, construct an onchain transfer transaction (USDC SPL token on Solana) to recipient. Let user sign it in wallet. After broadcast, send tx signature to your backend as payment_proof. Optionally wait for a few confirmations. 
Coinbase Developer Docs

For QR-pay demo: generate a universal link / deeplink that opens mobile wallet with prefilled transfer details; user completes payment on phone; then they return to page and provide tx signature.

Security & anti-abuse (important)

Always server-side verify payment before calling LLM. Never trust client-supplied payment proof.

Rate limit per wallet address and per IP. Use a small CAP of tokens per minute for unknown wallets.

Protect against replay: include request_id and require proofs to reference that request (or store accepted tx signature and reject reuse).

For scaling/production: add KYT/KYC via Coinbase x402 managed product if you accept real USDC at scale. 
Coinbase

Testing locally (testnet)

Use Solana devnet/testnet and a test USDC faucet for testing payments. Coinbase docs & Solana how-tos have testnet quickstarts for x402. Use small amounts. 
Coinbase Developer Docs
+1

Deployment checklist

Backend: deploy to Vercel/Render/Heroku/AWS. Ensure you have a persistent process for LLM streaming (Vercel serverless may complicate long SSE; pick a server that supports long-lived connections).

Database: Postgres (managed) for production; SQLite fine for hackathon.

Secrets: store provider keys, seller wallet private key (if needed) in environment variables — but seller wallet private key should ideally be a cold key; you only need recipient address to receive payments. Avoid exposing private keys.

Reconciliation & billing (post-demo)

Log provider token usage and costs (from LLM provider usage endpoints) and compare with received user payments to compute margins. Display a simple “revenue vs cost” dashboard in demo.

Demo features that impress judges (prioritize these)

Live streaming cost meter: show dollars consumed live as tokens stream. (Very visual + proves per-token billing.)

Multi-model compare: send one prompt to 2–3 models in parallel, show outputs + cost/latency per model.

Agent autopay demo: spawn a simple agent that autonomously pays and chains multiple LLM calls using x402 (autonomous payments are a canonical x402 use-case). 
Solana

On-chain receipt: show the transaction on Solana explorer and link directly from the UI.

Credit top-up UX: show a frictionless top-up → immediate queries flow.